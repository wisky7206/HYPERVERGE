{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: torch in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ransformers (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ransformers (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ransformers (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### RUNNING PHASE 2: SEMI-SUPERVISED LEARNING (FROM SCRATCH) ###\n",
      "Step 2.1: Configuring paths and parameters...\n",
      "Using class info from existing 'full_dataset' object.\n",
      "Test data directory: C:\\Users\\harkp\\Desktop\\HV-AI-2025\\HV-AI-2025\\test_images\n",
      "Confidence threshold set to: 0.95\n",
      "--------------------------------------------------\n",
      "Step 2.2: Loading Phase 1 model and generating pseudo-labels...\n",
      "Found 14800 unlabeled images to process.\n",
      "Generated 797 high-confidence pseudo-labels.\n",
      "--------------------------------------------------\n",
      "Step 2.3: Combining and SANITIZING original and pseudo-labeled data...\n",
      "Original labeled dataframe size: 779\n",
      "Sanitized labeled dataframe size (found images): 775\n",
      "Original pseudo-labels dataframe size: 797\n",
      "Sanitized pseudo-labels dataframe size (found images): 797\n",
      "Final combined dataset size: 1572\n",
      "--------------------------------------------------\n",
      "Step 2.4: Defining and fine-tuning the student model...\n",
      "Step 2.5: Starting student model training...\n",
      "Epoch 1/10 | Train Loss: 0.3864 | Val Loss: 0.2604 | Val Acc: 0.9407\n",
      "  -> Validation accuracy improved. Saving student model to phase2_student_model.pth\n",
      "Epoch 2/10 | Train Loss: 0.0977 | Val Loss: 0.1977 | Val Acc: 0.9534\n",
      "  -> Validation accuracy improved. Saving student model to phase2_student_model.pth\n",
      "Epoch 3/10 | Train Loss: 0.0696 | Val Loss: 0.2141 | Val Acc: 0.9492\n",
      "Epoch 4/10 | Train Loss: 0.0324 | Val Loss: 0.2021 | Val Acc: 0.9492\n",
      "Epoch 5/10 | Train Loss: 0.0219 | Val Loss: 0.2267 | Val Acc: 0.9407\n",
      "Epoch 6/10 | Train Loss: 0.0168 | Val Loss: 0.2091 | Val Acc: 0.9449\n",
      "Epoch 7/10 | Train Loss: 0.0127 | Val Loss: 0.2044 | Val Acc: 0.9619\n",
      "  -> Validation accuracy improved. Saving student model to phase2_student_model.pth\n",
      "Epoch 8/10 | Train Loss: 0.0113 | Val Loss: 0.2291 | Val Acc: 0.9534\n",
      "Epoch 9/10 | Train Loss: 0.0106 | Val Loss: 0.2259 | Val Acc: 0.9576\n",
      "Epoch 10/10 | Train Loss: 0.0046 | Val Loss: 0.2458 | Val Acc: 0.9492\n",
      "\n",
      "Phase 2 Training complete in 14m 31s\n",
      "Best student model validation accuracy: 0.9619\n",
      "--------------------------------------------------\n",
      "Step 2.6: Loading best student model and generating final predictions...\n",
      "Found 10477 images in C:\\Users\\harkp\\Desktop\\HV-AI-2025\\HV-AI-2025\\test_images to predict.\n",
      "Final predictions saved to C:\\Users\\harkp\\Desktop\\HV-AI-2025\\HV-AI-2025\\CSV jupyter notebook\\phase2_predictions.csv\n",
      "\n",
      "--- Final Prediction Results ---\n",
      "          path predicted_label\n",
      "0  0_1034.jpeg            cane\n",
      "1  0_1045.jpeg           gatto\n",
      "2  0_1085.jpeg           gatto\n",
      "3   0_110.jpeg            cane\n",
      "4  0_1104.jpeg            cane\n",
      "\n",
      "### PHASE 2 COMPLETE ###\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# PHASE 2: SEMI-SUPERVISED LEARNING (FROM SCRATCH & SANITIZED)\n",
    "# ==============================================================================\n",
    "# This cell contains the complete, corrected workflow for Phase 2.\n",
    "# It will:\n",
    "# 1. Sanitize the data by ensuring all referenced image files exist.\n",
    "# 2. Generate pseudo-labels for the unlabeled data using the Phase 1 model.\n",
    "# 3. Combine the original and pseudo-labeled data.\n",
    "# 4. Train a new, improved \"student\" model on the combined dataset.\n",
    "# 5. Use the student model to generate the final predictions.\n",
    "\n",
    "print(\"\\n### RUNNING PHASE 2: SEMI-SUPERVISED LEARNING (FROM SCRATCH) ###\")\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Step 2.1: Re-establish Configuration and Helper Variables\n",
    "# --------------------------------------------------------------------------\n",
    "print(\"Step 2.1: Configuring paths and parameters...\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# Ensure these variables from Phase 1 are correctly defined\n",
    "BASE_PATH = r'C:\\Users\\harkp\\Desktop\\HV-AI-2025\\HV-AI-2025'\n",
    "DATA_DIR = os.path.join(BASE_PATH, 'labeled_data', 'images')\n",
    "UNLABELED_DIR = os.path.join(BASE_PATH, 'unlabeled_data')\n",
    "CSV_PATH = os.path.join(BASE_PATH, 'labeled_data', 'labeled_data.csv')\n",
    "TEST_DIR = os.path.join(BASE_PATH, 'test_images') \n",
    "\n",
    "MODEL_PATH_PHASE1 = 'phase1_baseline_model.pth'\n",
    "MODEL_PATH_PHASE2 = 'phase2_student_model.pth'\n",
    "OUTPUT_CSV_DIR = os.path.join(BASE_PATH, 'CSV jupyter notebook')\n",
    "OUTPUT_CSV_PHASE2 = os.path.join(OUTPUT_CSV_DIR, 'phase2_predictions.csv')\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.95\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# We need the class mappings from the original dataset.\n",
    "# This code assumes 'full_dataset' and 'data_transforms' from Cell 1 exist.\n",
    "try:\n",
    "    idx_to_class = full_dataset.idx_to_class\n",
    "    num_classes = len(full_dataset.class_names)\n",
    "    print(\"Using class info from existing 'full_dataset' object.\")\n",
    "except NameError:\n",
    "    print(\"Recreating helper objects to get class info...\")\n",
    "    class LabeledDataset(Dataset):\n",
    "        def __init__(self, csv_path, img_dir, transform=None):\n",
    "            self.labels_df = pd.read_csv(csv_path)\n",
    "            self.img_dir = img_dir\n",
    "            self.transform = transform\n",
    "            self.class_names = sorted(self.labels_df.iloc[:, 1].unique())\n",
    "            self.class_to_idx = {name: i for i, name in enumerate(self.class_names)}\n",
    "            self.idx_to_class = {i: name for name, i in self.class_to_idx.items()}\n",
    "        def __len__(self): return len(self.labels_df)\n",
    "        def __getitem__(self, idx):\n",
    "            img_name = self.labels_df.iloc[idx, 0]\n",
    "            label_name = self.labels_df.iloc[idx, 1]\n",
    "            img_path = os.path.join(self.img_dir, img_name)\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            label_idx = self.class_to_idx[label_name]\n",
    "            if self.transform: image = self.transform(image)\n",
    "            return image, label_idx\n",
    "            \n",
    "    class TransformedDataset(Dataset):\n",
    "        def __init__(self, subset, transform):\n",
    "            self.subset = subset\n",
    "            self.transform = transform\n",
    "        def __getitem__(self, index):\n",
    "            x, y = self.subset[index]\n",
    "            return self.transform(x), y\n",
    "        def __len__(self): return len(self.subset)\n",
    "\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([transforms.Resize((224, 224)), transforms.RandomHorizontalFlip(), transforms.RandomRotation(10), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        'val': transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "    }\n",
    "    full_dataset = LabeledDataset(csv_path=CSV_PATH, img_dir=DATA_DIR)\n",
    "    idx_to_class = full_dataset.idx_to_class\n",
    "    num_classes = len(full_dataset.class_names)\n",
    "\n",
    "print(f\"Test data directory: {TEST_DIR}\")\n",
    "print(f\"Confidence threshold set to: {CONFIDENCE_THRESHOLD}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Step 2.2: Generate Pseudo-Labels\n",
    "# --------------------------------------------------------------------------\n",
    "print(\"Step 2.2: Loading Phase 1 model and generating pseudo-labels...\")\n",
    "\n",
    "teacher_model = models.resnet18(weights=None)\n",
    "num_ftrs = teacher_model.fc.in_features\n",
    "teacher_model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "teacher_model.load_state_dict(torch.load(MODEL_PATH_PHASE1))\n",
    "teacher_model = teacher_model.to(device)\n",
    "teacher_model.eval()\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "pseudo_labels = []\n",
    "\n",
    "unlabeled_image_files = [f for f in os.listdir(UNLABELED_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "print(f\"Found {len(unlabeled_image_files)} unlabeled images to process.\")\n",
    "\n",
    "for filename in unlabeled_image_files:\n",
    "    img_path = os.path.join(UNLABELED_DIR, filename)\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    image_tensor = data_transforms['val'](image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = teacher_model(image_tensor)\n",
    "        probabilities = softmax(outputs)\n",
    "        confidence, predicted_idx = torch.max(probabilities, 1)\n",
    "\n",
    "        if confidence.item() > CONFIDENCE_THRESHOLD:\n",
    "            predicted_class_name = idx_to_class[predicted_idx.item()]\n",
    "            pseudo_labels.append({'img_name': filename, 'label': predicted_class_name})\n",
    "\n",
    "print(f\"Generated {len(pseudo_labels)} high-confidence pseudo-labels.\")\n",
    "pseudo_labels_df = pd.DataFrame(pseudo_labels)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Step 2.3: Create and **SANITIZE** Combined Dataset (BUG FIX)\n",
    "# --------------------------------------------------------------------------\n",
    "print(\"Step 2.3: Combining and SANITIZING original and pseudo-labeled data...\")\n",
    "\n",
    "original_labels_df = pd.read_csv(CSV_PATH)\n",
    "original_labels_df.rename(columns={original_labels_df.columns[0]: 'img_name', original_labels_df.columns[1]: 'label'}, inplace=True)\n",
    "\n",
    "# --- Sanitization Step for Labeled Data ---\n",
    "print(f\"Original labeled dataframe size: {len(original_labels_df)}\")\n",
    "exists = original_labels_df['img_name'].apply(lambda x: os.path.exists(os.path.join(DATA_DIR, x)))\n",
    "original_labels_df = original_labels_df[exists].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "print(f\"Sanitized labeled dataframe size (found images): {len(original_labels_df)}\")\n",
    "original_labels_df['source_dir'] = DATA_DIR\n",
    "\n",
    "# --- Sanitization Step for Pseudo-Labeled Data ---\n",
    "if not pseudo_labels_df.empty:\n",
    "    print(f\"Original pseudo-labels dataframe size: {len(pseudo_labels_df)}\")\n",
    "    exists_pseudo = pseudo_labels_df['img_name'].apply(lambda x: os.path.exists(os.path.join(UNLABELED_DIR, x)))\n",
    "    pseudo_labels_df = pseudo_labels_df[exists_pseudo].copy()\n",
    "    print(f\"Sanitized pseudo-labels dataframe size (found images): {len(pseudo_labels_df)}\")\n",
    "    pseudo_labels_df['source_dir'] = UNLABELED_DIR\n",
    "\n",
    "# Combine the two sanitized dataframes\n",
    "combined_labels_df = pd.concat([original_labels_df, pseudo_labels_df], ignore_index=True)\n",
    "\n",
    "print(f\"Final combined dataset size: {len(combined_labels_df)}\")\n",
    "\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, df, class_to_idx, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = class_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx]['img_name']\n",
    "        label_name = self.df.iloc[idx]['label']\n",
    "        source_dir = self.df.iloc[idx]['source_dir']\n",
    "        img_path = os.path.join(source_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label_idx = self.class_to_idx[label_name]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label_idx\n",
    "\n",
    "combined_full_dataset = CombinedDataset(combined_labels_df, class_to_idx=full_dataset.class_to_idx)\n",
    "train_size_2 = int(0.85 * len(combined_full_dataset))\n",
    "val_size_2 = len(combined_full_dataset) - train_size_2\n",
    "train_subset_2, val_subset_2 = random_split(combined_full_dataset, [train_size_2, val_size_2])\n",
    "\n",
    "train_dataset_2 = TransformedDataset(train_subset_2, data_transforms['train'])\n",
    "val_dataset_2 = TransformedDataset(val_subset_2, data_transforms['val'])\n",
    "\n",
    "train_loader_2 = DataLoader(train_dataset_2, batch_size=32, shuffle=True)\n",
    "val_loader_2 = DataLoader(val_dataset_2, batch_size=32, shuffle=False)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Step 2.4: Fine-Tune the Student Model\n",
    "# --------------------------------------------------------------------------\n",
    "print(\"Step 2.4: Defining and fine-tuning the student model...\")\n",
    "\n",
    "student_model = models.resnet18(weights=None)\n",
    "student_model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "student_model.load_state_dict(torch.load(MODEL_PATH_PHASE1))\n",
    "student_model = student_model.to(device)\n",
    "\n",
    "for param in student_model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "params_to_update = [param for param in student_model.parameters() if param.requires_grad]\n",
    "optimizer_2 = optim.Adam(params_to_update, lr=0.0001)\n",
    "criterion_2 = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Step 2.5: Starting student model training...\")\n",
    "start_time_2 = time.time()\n",
    "num_epochs_2 = 10\n",
    "best_val_acc_2 = 0.0\n",
    "\n",
    "for epoch in range(num_epochs_2):\n",
    "    student_model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader_2:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer_2.zero_grad()\n",
    "        outputs = student_model(inputs)\n",
    "        loss = criterion_2(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_2.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader_2.dataset)\n",
    "\n",
    "    student_model.eval()\n",
    "    val_loss = 0.0\n",
    "    corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader_2:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = student_model(inputs)\n",
    "            loss = criterion_2(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            corrects += torch.sum(preds == labels.data)\n",
    "    epoch_val_loss = val_loss / len(val_loader_2.dataset)\n",
    "    epoch_val_acc = corrects.double() / len(val_loader_2.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs_2} | Train Loss: {epoch_loss:.4f} | Val Loss: {epoch_val_loss:.4f} | Val Acc: {epoch_val_acc:.4f}\")\n",
    "\n",
    "    if epoch_val_acc > best_val_acc_2:\n",
    "        best_val_acc_2 = epoch_val_acc\n",
    "        torch.save(student_model.state_dict(), MODEL_PATH_PHASE2)\n",
    "        print(f\"  -> Validation accuracy improved. Saving student model to {MODEL_PATH_PHASE2}\")\n",
    "\n",
    "training_time_2 = time.time() - start_time_2\n",
    "print(f\"\\nPhase 2 Training complete in {training_time_2 // 60:.0f}m {training_time_2 % 60:.0f}s\")\n",
    "print(f\"Best student model validation accuracy: {best_val_acc_2:.4f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Step 2.6: Generate Final Predictions with Student Model\n",
    "# --------------------------------------------------------------------------\n",
    "print(\"Step 2.6: Loading best student model and generating final predictions...\")\n",
    "\n",
    "final_model = models.resnet18(weights=None)\n",
    "final_model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "final_model.load_state_dict(torch.load(MODEL_PATH_PHASE2))\n",
    "final_model = final_model.to(device)\n",
    "final_model.eval()\n",
    "\n",
    "final_predictions = []\n",
    "test_image_files = [f for f in os.listdir(TEST_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "print(f\"Found {len(test_image_files)} images in {TEST_DIR} to predict.\")\n",
    "\n",
    "for filename in test_image_files:\n",
    "    img_path = os.path.join(TEST_DIR, filename)\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    image_tensor = data_transforms['val'](image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = final_model(image_tensor)\n",
    "        _, predicted_idx = torch.max(outputs, 1)\n",
    "        predicted_class_name = idx_to_class[predicted_idx.item()]\n",
    "    \n",
    "    final_predictions.append({'path': filename, 'predicted_label': predicted_class_name})\n",
    "        \n",
    "final_pred_df = pd.DataFrame(final_predictions)\n",
    "os.makedirs(os.path.dirname(OUTPUT_CSV_PHASE2), exist_ok=True)\n",
    "final_pred_df.to_csv(OUTPUT_CSV_PHASE2, index=False)\n",
    "print(f\"Final predictions saved to {OUTPUT_CSV_PHASE2}\")\n",
    "\n",
    "if not final_pred_df.empty:\n",
    "    print(\"\\n--- Final Prediction Results ---\")\n",
    "    print(final_pred_df.head())\n",
    "\n",
    "print(\"\\n### PHASE 2 COMPLETE ###\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1141155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\harkp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ransformers (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ransformers (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ransformers (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\harkp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d9b9e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### RUNNING CELL 1: TRAINING ###\n",
      "Step 1: Configuring paths...\n",
      "Image data directory: C:\\Users\\harkp\\Desktop\\HV-AI-2025\\HV-AI-2025\\labeled_data\\images\n",
      "Labels CSV path: C:\\Users\\harkp\\Desktop\\HV-AI-2025\\HV-AI-2025\\labeled_data\\labeled_data.csv\n",
      "--------------------------------------------------\n",
      "Step 2: Defining Custom Dataset and DataLoaders...\n",
      "Dataset ready. Found 10 classes.\n",
      "--------------------------------------------------\n",
      "Step 3: Defining the ResNet-18 model...\n",
      "Using device: cpu\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\harkp/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44.7M/44.7M [00:02<00:00, 15.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model definition complete.\n",
      "--------------------------------------------------\n",
      "Step 4: Starting model training...\n",
      "Epoch 1/10 | Train Loss: 2.0596 | Val Loss: 1.6467 | Val Acc: 0.4936\n",
      "  -> Validation accuracy improved. Saving model to phase1_baseline_model.pth\n",
      "Epoch 2/10 | Train Loss: 1.4348 | Val Loss: 1.1177 | Val Acc: 0.6538\n",
      "  -> Validation accuracy improved. Saving model to phase1_baseline_model.pth\n",
      "Epoch 3/10 | Train Loss: 1.0799 | Val Loss: 0.8161 | Val Acc: 0.8077\n",
      "  -> Validation accuracy improved. Saving model to phase1_baseline_model.pth\n",
      "Epoch 4/10 | Train Loss: 0.8763 | Val Loss: 0.6991 | Val Acc: 0.8141\n",
      "  -> Validation accuracy improved. Saving model to phase1_baseline_model.pth\n",
      "Epoch 5/10 | Train Loss: 0.7346 | Val Loss: 0.6213 | Val Acc: 0.8397\n",
      "  -> Validation accuracy improved. Saving model to phase1_baseline_model.pth\n",
      "Epoch 6/10 | Train Loss: 0.6594 | Val Loss: 0.5432 | Val Acc: 0.8654\n",
      "  -> Validation accuracy improved. Saving model to phase1_baseline_model.pth\n",
      "Epoch 7/10 | Train Loss: 0.6111 | Val Loss: 0.4841 | Val Acc: 0.8718\n",
      "  -> Validation accuracy improved. Saving model to phase1_baseline_model.pth\n",
      "Epoch 8/10 | Train Loss: 0.5638 | Val Loss: 0.4893 | Val Acc: 0.8654\n",
      "Epoch 9/10 | Train Loss: 0.5242 | Val Loss: 0.4290 | Val Acc: 0.8846\n",
      "  -> Validation accuracy improved. Saving model to phase1_baseline_model.pth\n",
      "Epoch 10/10 | Train Loss: 0.4833 | Val Loss: 0.4149 | Val Acc: 0.8974\n",
      "  -> Validation accuracy improved. Saving model to phase1_baseline_model.pth\n",
      "\n",
      "Training complete in 2m 51s\n",
      "Best validation accuracy: 0.8974\n",
      "### FINISHED CELL 1 ###\n"
     ]
    }
   ],
   "source": [
    "print(\"### RUNNING CELL 1: TRAINING ###\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Step 1: Setup and Path Configuration\n",
    "# --------------------------------------------------------------------------\n",
    "print(\"Step 1: Configuring paths...\")\n",
    "\n",
    "# !!! IMPORTANT !!!\n",
    "# Update this base path to match your project's main folder.\n",
    "BASE_PATH = r'C:\\Users\\harkp\\Desktop\\HV-AI-2025\\HV-AI-2025'\n",
    "\n",
    "DATA_DIR = os.path.join(BASE_PATH, 'labeled_data', 'images')\n",
    "CSV_PATH = os.path.join(BASE_PATH, 'labeled_data', 'labeled_data.csv')\n",
    "MODEL_SAVE_PATH = 'phase1_baseline_model.pth'\n",
    "\n",
    "print(f\"Image data directory: {DATA_DIR}\")\n",
    "print(f\"Labels CSV path: {CSV_PATH}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Step 2: Custom Dataset and DataLoaders\n",
    "# --------------------------------------------------------------------------\n",
    "print(\"Step 2: Defining Custom Dataset and DataLoaders...\")\n",
    "\n",
    "class LabeledDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for reading image paths and labels from a CSV.\"\"\"\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "        self.labels_df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.class_names = sorted(self.labels_df['label'].unique())\n",
    "        self.class_to_idx = {name: i for i, name in enumerate(self.class_names)}\n",
    "        self.idx_to_class = {i: name for name, i in self.class_to_idx.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.labels_df.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label_name = self.labels_df.iloc[idx, 1]\n",
    "        label_idx = self.class_to_idx[label_name]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label_idx\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "full_dataset = LabeledDataset(csv_path=CSV_PATH, img_dir=DATA_DIR)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_subset, val_subset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "class TransformedDataset(Dataset):\n",
    "    def __init__(self, subset, transform):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        return self.transform(x), y\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "train_dataset = TransformedDataset(train_subset, data_transforms['train'])\n",
    "val_dataset = TransformedDataset(val_subset, data_transforms['val'])\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "num_classes = len(full_dataset.class_names)\n",
    "print(f\"Dataset ready. Found {num_classes} classes.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Step 3: Model Definition (ResNet-18)\n",
    "# --------------------------------------------------------------------------\n",
    "print(\"Step 3: Defining the ResNet-18 model...\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "model = model.to(device)\n",
    "print(\"Model definition complete.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Step 4: Training the Model\n",
    "# --------------------------------------------------------------------------\n",
    "print(\"Step 4: Starting model training...\")\n",
    "start_time = time.time()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            corrects += torch.sum(preds == labels.data)\n",
    "    epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "    epoch_val_acc = corrects.double() / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {epoch_loss:.4f} | Val Loss: {epoch_val_loss:.4f} | Val Acc: {epoch_val_acc:.4f}\")\n",
    "\n",
    "    if epoch_val_acc > best_val_acc:\n",
    "        best_val_acc = epoch_val_acc\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(f\"  -> Validation accuracy improved. Saving model to {MODEL_SAVE_PATH}\")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\nTraining complete in {training_time // 60:.0f}m {training_time % 60:.0f}s\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "print(\"### FINISHED CELL 1 ###\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc956d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image directory: C:\\Users\\harkp\\Desktop\\HV-AI-2025\\HV-AI-2025\\test_images\n",
      "Model path: phase1_baseline_model.pth\n",
      "Predictions will be saved to: C:\\Users\\harkp\\Desktop\\HV-AI-2025\\HV-AI-2025\\CSV\\phase1_predictions.csv\n",
      "--------------------------------------------------\n",
      "Step 2: Loading model and generating predictions...\n",
      "Found 10477 images in C:\\Users\\harkp\\Desktop\\HV-AI-2025\\HV-AI-2025\\test_images\n",
      "Predictions saved to C:\\Users\\harkp\\Desktop\\HV-AI-2025\\HV-AI-2025\\CSV\\phase1_predictions.csv\n",
      "\n",
      "--- Prediction Results ---\n",
      "          path predicted_label\n",
      "0  0_1034.jpeg            cane\n",
      "1  0_1045.jpeg           ragno\n",
      "2  0_1085.jpeg           gatto\n",
      "3   0_110.jpeg            cane\n",
      "4  0_1104.jpeg           ragno\n",
      "### FINISHED CELL 2 ###\n"
     ]
    }
   ],
   "source": [
    "### RUNNING CELL 2: TESTING ###\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Step 1: Path Configuration for Testing\n",
    "# --------------------------------------------------------------------------\n",
    "# Use the absolute path to your folder containing the test images.\n",
    "TEST_DIR = r'C:\\Users\\harkp\\Desktop\\HV-AI-2025\\HV-AI-2025\\test_images'\n",
    "\n",
    "# The model file path remains the same, assuming it's in the same directory as the script.\n",
    "MODEL_PATH = 'phase1_baseline_model.pth' \n",
    "\n",
    "# Define the full path for the output CSV file, including the filename.\n",
    "OUTPUT_CSV = r'C:\\Users\\harkp\\Desktop\\HV-AI-2025\\HV-AI-2025\\CSV\\phase1_predictions.csv'\n",
    "\n",
    "# Ensure the directory for the output CSV exists\n",
    "# This line automatically creates the 'CSV to store new predicted csv' folder if it doesn't exist.\n",
    "output_dir = os.path.dirname(OUTPUT_CSV)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Test image directory: {TEST_DIR}\")\n",
    "print(f\"Model path: {MODEL_PATH}\")\n",
    "print(f\"Predictions will be saved to: {OUTPUT_CSV}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Step 2: Load Model and Generate Predictions\n",
    "# --------------------------------------------------------------------------\n",
    "# (The rest of your code remains the same)\n",
    "print(\"Step 2: Loading model and generating predictions...\")\n",
    "\n",
    "# The 'full_dataset' and 'num_classes' variables are available from Cell 1\n",
    "idx_to_class = full_dataset.idx_to_class\n",
    "\n",
    "# Initialize the model architecture\n",
    "prediction_model = models.resnet18(weights=None)\n",
    "num_ftrs = prediction_model.fc.in_features\n",
    "prediction_model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Load the saved model weights\n",
    "try:\n",
    "    prediction_model.load_state_dict(torch.load(MODEL_PATH))\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Model file not found at {MODEL_PATH}\")\n",
    "    print(\"Please run the training cell (Cell 1) first to generate the model file.\")\n",
    "else:\n",
    "    prediction_model = prediction_model.to(device)\n",
    "    prediction_model.eval()\n",
    "\n",
    "    # Use the validation transforms defined in Cell 1\n",
    "    test_transforms = data_transforms['val']\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    test_image_files = [f for f in os.listdir(TEST_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    print(f\"Found {len(test_image_files)} images in {TEST_DIR}\")\n",
    "\n",
    "    for filename in test_image_files:\n",
    "        img_path = os.path.join(TEST_DIR, filename)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image_tensor = test_transforms(image).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = prediction_model(image_tensor)\n",
    "            _, predicted_idx = torch.max(outputs, 1)\n",
    "            predicted_class_name = idx_to_class[predicted_idx.item()]\n",
    "        \n",
    "        predictions.append({'path': filename, 'predicted_label': predicted_class_name})\n",
    "            \n",
    "    pred_df = pd.DataFrame(predictions)\n",
    "    pred_df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"Predictions saved to {OUTPUT_CSV}\")\n",
    "    \n",
    "    if not pred_df.empty:\n",
    "        print(\"\\n--- Prediction Results ---\")\n",
    "        print(pred_df.head())\n",
    "    else:\n",
    "        print(\"\\nNo test images were found to make predictions on.\")\n",
    "        \n",
    "print(\"### FINISHED CELL 2 ###\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
